{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed40500-7adf-4f54-bcba-4e5381200434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7848/3284889473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from numpy import array\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import callbacks,optimizers\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras .layers.core import Activation,Dropout,Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f6547-42ae-4cd4-8143-879fdd7dc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3daa6c-c8b1-4a27-9a50-e7d5cf5c94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "movie_reviews = shuffle(movie_reviews, random_state=42)\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cc668-7663-421f-ab37-6eb813081a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b633d-e1cb-4fda-9e37-b42e7678d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b771b-0a45-4cc0-b762-86ec9c95ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b79f3-4ea9-4625-92b4-a523e0509842",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews['review'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b986d4-3240-434b-8725-35ec6b30e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='sentiment', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419527f-9ece-4eff-88db-30e84718da33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de2814-24bb-498e-95b2-2023163e228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "    \n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    \n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\",' ', sentence)\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0672c-b16c-4b02-9f61-2fb9172c5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525922b-f64d-4851-a69f-df9d23eccf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351acc8-85d8-4335-bf3c-0a1adc696f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775ee68-1e64-4ed7-8006-5614946aa17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = movie_reviews['sentiment']\n",
    "\n",
    "y = np.array(list(map(lambda x: 1 if x ==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9746a-d7ef-42dc-82c2-9a98a114b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b025613-4f41-46a8-a870-d7c1a1d8c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69575a-515e-4947-9302-5425e2fa0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ad549-5c56-4785-990a-1840f05d883a",
   "metadata": {},
   "source": [
    "### Preparing the embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f8a1d-7acb-4d2d-8ab6-54e412938075",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa70f0-1426-4c83-a7c1-11de96531f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('new_tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95af091-1d3e-44e4-95f4-c490abd256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test,padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8197a0-0a99-495d-b083-a214350539d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dict = dict()\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = coefs\n",
    "glove_file.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f5d5e-2cbc-41e3-80c4-dd644d548194",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, index in  tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994207a-0d8f-4d23-a1e8-40a8ed2f3591",
   "metadata": {},
   "source": [
    "### Deep learning model\n",
    "+ using recurrent neural network\n",
    "   - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29051a82-eb9b-430a-b490-bba757125ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = Sequential()\n",
    "# embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "# model.add(embedding_layer)\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# print(model.summary())\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220817-b8a9-4334-8b90-674186cce51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=2, validation_split=0.2,callbacks=[checkpointer])\n",
    "# model = create_model(model)\n",
    "# elst = callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "# save_ck = callbacks.ModelCheckpoint(filepath=\"model_weights.hdf5\", verbose=1, save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5456d41-20d0-4b8f-a361-f9f2e4aef8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bf0e3-6a10-4eb9-aca6-c70439c14364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'model_weights.hdf5'\n",
    "# model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90207dc-646c-42c2-80f9-dcc00e043ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating performance of the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9badc3f-a883-4689-8adc-a0cc8100ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd39861-14fa-44f5-82a4-7146264cd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4333c74-eb57-45ac-b96f-6ff8290cb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X[100]\n",
    "instance = [instance]\n",
    "print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd34ac3-5c43-4d68-bc99-5fb924e89a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = [\n",
    "#     'This is an excellent movie',\n",
    "#     'The move was fantastic I like it',\n",
    "#     'You should watch it is brilliant',\n",
    "#     'Exceptionally good',\n",
    "#     'Wonderfully directed and executed I like it',\n",
    "#     'Its a fantastic series',\n",
    "#     'Never watched such a brillent movie',\n",
    "#     'It is a Wonderful movie',\n",
    "    \n",
    "#      \"horrible acting\",\n",
    "#     'waste of money',\n",
    "#     'pathetic picture',\n",
    "#     'It was very boring',\n",
    "#     'I did not like the movie',\n",
    "#     'The movie was horrible',\n",
    "#     'I will not recommend',\n",
    "#     'The acting is pathetic'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d526168-4702-4f93-8928-620e6bb1b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance1 = ['good']\n",
    "instance = tokenizer.texts_to_sequences(instance)\n",
    "\n",
    "flat_list = []\n",
    "for sublist in instance:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "flat_list = [flat_list]\n",
    "\n",
    "instance = pad_sequences(flat_list, padding='post', maxlen=maxlen)\n",
    "\n",
    "predict = model.predict(instance)\n",
    "# predict\n",
    "\n",
    "if predict.any() > 0.5:\n",
    "    print('positive')\n",
    "elif predict.any() < 0.5:\n",
    "    print('negative')\n",
    "else:\n",
    "    print('neutral')\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5a041-4e90-4bff-9ea4-f94a1d0b9151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classes = model.predict_classes(X_test, batch_size=128)\n",
    "proba=model.predict(X_test, batch_size=128)\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c9f6f-e7e9-41a8-aed9-29c4949fb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc6506-6a33-4bd4-8efa-935b5c094f43",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba726f9-e84c-4e01-9749-564828cbdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')\n",
    "model.save('new_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f69e78-db16-452d-b935-1a718cf0b532",
   "metadata": {},
   "source": [
    "### saving tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113c64c-ddd9-4e12-9e75-2df99fdd242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('tokenizer.pkl', 'wb') as handle:\n",
    "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a25d0-52f3-404e-945e-d5dd81e7c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "new_model = load_model('new_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6e1c5-b4b1-49a5-8930-b9ea5dad9525",
   "metadata": {},
   "source": [
    "### loading tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd0000-2990-4fce-baad-12cb33859632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tokenizer.pkl', 'rb') as handle:\n",
    "#     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470f5ab-da55-4fa4-b217-9c8a1ec5a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instancen = input()\n",
    "instancen = [instancen]\n",
    "instancen = tokenizer.texts_to_sequences(instancen)\n",
    "\n",
    "flat_list = []\n",
    "for sublist in instancen:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "flat_list = [flat_list]\n",
    "\n",
    "instancen = pad_sequences(flat_list, padding='post', maxlen=100)\n",
    "\n",
    "predict = new_model.predict(instancen)\n",
    "print(predict)\n",
    "\n",
    "for i in range(len(predict)):\n",
    "#     print(\"Predicted sentiemnt:\")\n",
    "    for idx, val in enumerate(predict[i]):\n",
    "        if val >= 0.5:\n",
    "            print('POSITIVE')\n",
    "        else:\n",
    "            print('NEGATIVE')\n",
    "       \n",
    "        \n",
    "# if predict > \"0.5:\n",
    "#     print('positive')\n",
    "# elif predict < 0.5:\n",
    "#     print('negative')\n",
    "# else:\n",
    "#     print('neutral')\n",
    "# print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf10db-53df-447b-b15e-8527bafb64d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546456fb-e510-4b13-a063-6d3cdd942b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
